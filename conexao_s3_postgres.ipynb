{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Conexão entre Bucket S3 e banco de dados Postgres no RDS\n",
    "Este projeto consiste em ler um bucket S3 com arquivos de imagens, e armazenar os nomes dessas imagens em um banco de dados (RDS)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o ambiente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Instalar a biblioteca **python-dotenv** para trabalhar com variáveis de ambiente, a fim de proteger dados sensíveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Importar as variáveis de ambiente do arquivo **.env** no mesmo diretório"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa um método da biblioteca dotenv\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Carrega as variáveis de ambiente do arquivo .env\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando o banco de dados padrão, para, a partir dele, começar a trabalhar\n",
    "Neste caso, é criado o database \"postgres\", e a partir dele, é possível criar o database \"inventário\", que é o que iremos trabalhar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Importar biblioteca **psycopg2** para possiblitar conexão com bancos de dados Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install psycopg2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Realizar a conexão com o banco de dados Postgres no RDS, e criar um database chamado **\"inventário\"** dentro dele, onde serão armazenados os arquivos do Bucket S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2 #lib para possibilitar conexão com algum BD Postgres\n",
    "\n",
    "db_host = os.environ.get('DB_HOST') # pegando o host (endpoint RDS) das variáveis de ambiente\n",
    "db_user = os.environ.get('DB_USER') # pegando o usuário do BD RDS das variáveis de ambiente\n",
    "db_password = os.environ.get('DB_PASSWORD') # pegando a senha do usuário do BD RDS das variáveis de ambiente\n",
    "\n",
    "conexaoBd = psycopg2.connect(host=db_host, database='postgres',\n",
    "                             user=db_user, password=db_password)\n",
    "# host -> endpoint do BD, endereço desse banco\n",
    "# database -> BD em que se quer conectar, como não existe nenhum criado ainda, utilizou-se o BD default \"postgres\"\n",
    "# user -> usuário para acessar o BD (configurado na criação do banco, geralmente é postgres mesmo, pois não tem BD criado ainda)\n",
    "# password -> senha definida na criação do BD\n",
    "\n",
    "conexaoBd.autocommit = True # transações commitadas automaticamente\n",
    "\n",
    "cursor = conexaoBd.cursor() # objeto para realizar consultas no banco de dados, no caso a var cursor será o cursor do conexaoBD, que é a conexão\n",
    "                            # do BD feita anteriormente\n",
    "\n",
    "cursor.execute('create database inventario;') # via cursor, está executando um create database para criar o BD inventário\n",
    "\n",
    "conexaoBd.close() # fecha a conexão, senão ela fica aberta para sempre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando tabela no banco de dados invetário criado anteriormente\n",
    "Cria a tabela onde serão armazenados os arquivos, com os campos necessários \"id do arquivo\" e \"nome do arquivo\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Ao criar a tabela **arquivos**, dentro do banco de dados inventário, é definido quais campos ela terá. No caso, ela terá um campo de inteiros onde terá os identificadores (ids) de cada arquivo e um campo de caracteres (varchar(256)) com o nome do arquivo presente no Bucket S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2 #lib para possibilitar conexão com algum BD Postgres\n",
    "\n",
    "conexaoBd = psycopg2.connect(host=db_host, database='inventario',\n",
    "                             user=db_user, password=db_password)\n",
    "# database -> BD em que se quer conectar, no caso o criado anteriormente \"inventário\"\n",
    "\n",
    "conexaoBd.autocommit = True\n",
    "\n",
    "cursor = conexaoBd.cursor()\n",
    "\n",
    "cursor.execute('create table arquivos (idarquivo INT, nomearquivo VARCHAR(256));') # via cursor, está executando um create table\n",
    "                                                                                # para criar a tabela onde serão armazenadas o ID do arquivo e o nome\n",
    "\n",
    "conexaoBd.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conectar ao bucket S3 onde estão os arquivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Instalar a lib **boto3** para comunicar com serviços AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Conectar com o Bucket S3 e listar os arquivos que estão presentes nele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3 # lib para comunicar com serviços AWS\n",
    "\n",
    "s3_region = os.environ.get('S3_REGION') # pegando a região do S3 das variáveis de ambiente\n",
    "aws_access_key_id = os.environ.get('AWS_ACCESS_KEY_ID') # pegando a chave de acesso AWS das variáveis de ambiente\n",
    "aws_secret_access_key = os.environ.get('AWS_SECRET_ACCESS_KEY') # pegando a chave secreta de acesso AWS das variáveis de ambiente\n",
    "\n",
    "s3 = boto3.resource( # identificando qual serviço da AWS irei utilizar aqui, no caso, o s3, realizando a \"conexão\" com esse serviço AWS\n",
    "    service_name = 's3', # nome do serviço = s3\n",
    "    region_name = s3_region, # região onde meu bucket está\n",
    "    aws_access_key_id = aws_access_key_id, # chave de acesso AWS criada\n",
    "    aws_secret_access_key = aws_secret_access_key # chave de acesso AWS privada\n",
    ")\n",
    "\n",
    "bucket_name = os.environ.get('BUCKET_NAME') # pegando o nome do bucket das variáveis de ambiente\n",
    "bucket_prefix = os.environ.get('BUCKET_PREFIX') # pegando o prefixo (pasta) dentro do bucket das variáveis de ambiente\n",
    "\n",
    "for objects_s3 in s3.Bucket(bucket_name).objects.filter(Prefix=bucket_prefix):\n",
    "  # objects_s3 -> variável de controle do for | s3.Bucket(bucket) -> identifica o bucket | objects.filter(Prefix=prefix) -> filtra pela pasta definida\n",
    "  if objects_s3.key.endswith('jpg') or objects_s3.key.endswith('JPG'): # key -> nome do arquivo\n",
    "    filename = objects_s3.key.split('/')[1]\n",
    "    print(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Gravar no BD Postgres, que está no RDS, os nomes dos arquivos que estão no Bucket S3 com um identificador incremental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource( # identificando qual serviço da AWS irei utilizar aqui, no caso, o s3, realizando a \"conexão\" com esse serviço AWS\n",
    "    service_name = 's3', # nome do serviço = s3\n",
    "    region_name = s3_region, # região onde meu bucket está\n",
    "    aws_access_key_id = aws_access_key_id, # chave de acesso AWS criada\n",
    "    aws_secret_access_key = aws_secret_access_key # chave de acesso AWS privada\n",
    ")\n",
    "\n",
    "# CONECTAR COM O BD POSTGRES\n",
    "conexaoBd = psycopg2.connect(host=db_host, database='inventario', user=db_user, password=db_password)\n",
    "\n",
    "conexaoBd.autocommit = True\n",
    "\n",
    "cursor = conexaoBd.cursor()\n",
    "\n",
    "id = 0 # criando o identificador a ser adicionado na tabela, que será incremental\n",
    "\n",
    "for objects_s3 in s3.Bucket(bucket_name).objects.filter(Prefix=bucket_prefix):\n",
    "    if objects_s3.key.endswith('jpg') or objects_s3.key.endswith('JPG'): # key -> nome do arquivo\n",
    "        filename = objects_s3.key.split('/')[1]\n",
    "        id += 1\n",
    "        cursor.execute(\"insert into arquivos (idarquivo,nomearquivo) values (\" + str(id) + \",'\" + filename + \"')\")\n",
    "\n",
    "conexaoBd.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Verificar se ocorreu a inserção dos dados no BD Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conexaoBd = psycopg2.connect(host=db_host, database='inventario', user=db_user, password=db_password)\n",
    "\n",
    "conexaoBd.autocommit = True\n",
    "\n",
    "cursor = conexaoBd.cursor() \n",
    "\n",
    "cursor.execute('select * from arquivos;')\n",
    "\n",
    "todosArquivosTabelaBD = cursor.fetchall() # pega todos os itens da tabela arquivos (q foi feito o select antes) e coloca na var todosArquivosTabelaBD\n",
    "\n",
    "for item in todosArquivosTabelaBD:\n",
    "    print(item)\n",
    "\n",
    "conexaoBd.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
